{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gw3eZLKkU-fP",
        "UQMO4b6u007D",
        "izNSmtGue7gD",
        "k---xJS96EJu",
        "91W7wg7b6HY9",
        "zvGoy2ehzcQu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesarea Datelor\n",
        "\n",
        "Limbajul scris conÈ›ine multe elemente care nu relevÄƒ informaÈ›ie neapÄƒrat relevantÄƒ pentru taskul curent. De multe ori este mai bine sÄƒ eliminÄƒm declinÄƒrile, punctuaÈ›ia, numerele etc. din modelarea textului. DepinzÃ¢nd de problema curentÄƒ, putem alege una sau mai multe metode de curÄƒÈ›are a textului:\n",
        "- Tokenizarea textului\n",
        "- Transformarea Ã®n litere mici\n",
        "- Eliminarea cifrelor / numerelor sau transformarea lor Ã®n cuvinte\n",
        "- Eliminarea linkurilor [LINK]\n",
        "- Eliminarea userilor (@) [USER]\n",
        "- Eliminarea sau Ã®nlocuirea hashtagurilor (#)\n",
        "- Eliminarea sau transformarea Ã®n cuvinte a emoticoanelor ( :) :D) È™i a emojiurilor (ğŸ’™ ğŸ±)\n",
        "- Eliminarea punctuaÈ›iei\n",
        "- Eliminarea cuvintelor comune din limbÄƒ (stopwords)\n",
        "- Stemming / lemmatizare"
      ],
      "metadata": {
        "id": "U3sSizRnguC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RegEx\n",
        "\n",
        "Un [RegEx](https://www.w3schools.com/python/python_regex.asp) (_Regular Expression_ / _Expresie RegulatÄƒ_) reprezintÄƒ un È™ir de caractere care defineÈ™te un È™ablon de cÄƒutare. Poate fi folosit pentru a identifica un subÈ™ir Ã®ntr-un string, pentru a-l Ã®nlocui sau pentru a Ã®mpÄƒrÈ›i textul Ã®n jurul lui.\n",
        "\n",
        "PuteÈ›i vedea cum funcÈ›ioneazÄƒ un regex pe un text anume folosind acest link: https://pythex.org/."
      ],
      "metadata": {
        "id": "gw3eZLKkU-fP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "txt = \"The rain   in Spain stays mainly   in the plain\"\n",
        "x = re.search(\"Spai.\", txt)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY3TpT-V5QX3",
        "outputId": "8e694c48-5141-44af-c7e9-fb40430abcbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(14, 19), match='Spain'>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CÄƒutarea unui string nu returneazÄƒ nimic dacÄƒ nu gÄƒseÈ™te niciun match, altfel returneazÄƒ un obiect cu matchul exact È™i poziÈ›ia la care se aflÄƒ. Stringul devine relevant cÃ¢nd folosim alte simboluri pentru pattern matching, cum ar fi:\n",
        "- . - orice caracter\n",
        "- \\+ - mai multe apariÈ›ii ale caracterului anterior\n",
        "- \\* - un numÄƒr nedefinit de apariÈ›ii are caracterului anterior, incluzÃ¢nd 0"
      ],
      "metadata": {
        "id": "6XX0_VEtWJAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = re.split(\" +.\", txt)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37jcxol7D7yu",
        "outputId": "95b6de60-e634-4cc0-c267-ef854f494185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'ain', 'n', 'pain', 'tays', 'ainly', 'n', 'he', 'lain']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alte caractere speciale:\n",
        "- \\d - cifre\n",
        "- \\D - nu cifre\n",
        "- \\s - spaÈ›iu\n",
        "- \\S - nu spaÈ›iu\n",
        "- \\w - litere mici, majuscule, caracterul \"_\"\n",
        "- \\W - tot ce nu e \\w\n",
        "- [a-m] - setul de caractere din interior. Poate include intervale\n",
        "\n",
        "LibrÄƒria completÄƒ poate fi gÄƒsitÄƒ aici https://docs.python.org/3/library/re.html."
      ],
      "metadata": {
        "id": "7c-ppOwgEszZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Putem folosi un regex sÄƒ identificÄƒm toate cuvintele care includ secvenÈ›a \"ai\":\n"
      ],
      "metadata": {
        "id": "iZBBAPXQtMAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = re.findall(\"\\w*ai\\w\", txt)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxme5CAus_uJ",
        "outputId": "95945a8f-db88-4895-90c1-f2d55e8b850d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rain', 'Spain', 'main', 'plain']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizare\n",
        "\n",
        "Tokenizarea este procesul de Ã®mpÄƒrÈ›ire a textului Ã®n _tokens_. Tokenii nu sunt neapÄƒrat cuvinte sau propoziÈ›ii, ci o secvenÈ›Äƒ de caractere Ã®mpÄƒrÈ›ite dupÄƒ o anumitÄƒ regulÄƒ."
      ],
      "metadata": {
        "id": "cbpK2r2z6mgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pentru urmÄƒtoarele exerciÈ›ii vom folosi un corpus din [NLTK](https://www.nltk.org/) pentru analiza sentimentelor."
      ],
      "metadata": {
        "id": "y9ab1d6c0vAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import twitter_samples\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('twitter_samples')\n",
        "tweets = twitter_samples.strings('positive_tweets.json')\n",
        "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "tweets"
      ],
      "metadata": {
        "id": "xFT9RrgQ0vAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import sent_tokenize, word_tokenize\n",
        "\n",
        "print(tweets[6])\n",
        "print(sent_tokenize(tweets[6]))\n",
        "print(word_tokenize(tweets[6]))"
      ],
      "metadata": {
        "id": "2wMg2p2bFSkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb55fafd-9124-47e0-9aa9-343d124f8a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We don't like to keep our lovely customers waiting for long! We hope you enjoy! Happy Friday! - LWWF :) https://t.co/smyYriipxI\n",
            "[\"We don't like to keep our lovely customers waiting for long!\", 'We hope you enjoy!', 'Happy Friday!', '- LWWF :) https://t.co/smyYriipxI']\n",
            "['We', 'do', \"n't\", 'like', 'to', 'keep', 'our', 'lovely', 'customers', 'waiting', 'for', 'long', '!', 'We', 'hope', 'you', 'enjoy', '!', 'Happy', 'Friday', '!', '-', 'LWWF', ':', ')', 'https', ':', '//t.co/smyYriipxI']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ObservaÈ›i cum nltk desparte cuvÃ¢ntul \"don't\". Alte tokenizatoare Ã®l pot pÄƒstra Ã®ntreg. Acesta este un exemplu de decizie de tokenizare care trebuie fÄƒcutÄƒ."
      ],
      "metadata": {
        "id": "X_R5Pa8Q2Rxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Emoticoane & emojiuri\n",
        "\n",
        "Tokenizarea se bazeazÄƒ de obicei pe spaÈ›ii È™i punctuaÈ›ie, ceea ce Ã®nseamnÄƒ cÄƒ nu È™tie sÄƒ gestioneze emoticoanele. O variantÄƒ este sÄƒ ne creÄƒm propriul regex care sÄƒ identifice simbolurile sÄƒ sÄƒ le Ã®nlocuiascÄƒ cu emoÈ›ia corespunzÄƒtoare.\n",
        "\n",
        "Un scurt exemplu:"
      ],
      "metadata": {
        "id": "izNSmtGue7gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emoticons = {\n",
        "    \"happy\": r\":[\\)|D+]\",\n",
        "    \"laugh\": r\":\\)\\)+\",\n",
        "    \"sad\": r\":\\(+\"\n",
        "}"
      ],
      "metadata": {
        "id": "JVKGAPTzKrwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pentru emoticoane putem folosi biblioteca [emoji](https://pypi.org/project/emoji/):"
      ],
      "metadata": {
        "id": "dL_3jA0j-HrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2jGoaJnQUGD",
        "outputId": "435cad4b-5ad3-4e66-8cdb-bf8d562b9f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/358.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m358.4/358.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji\n",
        "\n",
        "print(tweets[24])\n",
        "emoji.demojize(tweets[24])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MgVVPDioOeFx",
        "outputId": "0bd32ca5-e94f-447f-fec2-ba56484c5a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’…ğŸ½ğŸ’‹ - :)))) haven't seen you in years\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\":nail_polish_medium_skin_tone::kiss_mark: - :)))) haven't seen you in years\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lematizare vs. Stemming\n",
        "\n",
        "De cele mai multe ori formatul exact Ã®n care apare un text nu este relevant, ci ne intereseazÄƒ mai mult informaÈ›ia pe care o transmite È™i frecvenÈ›a sa Ã®n text. Din acest motiv putem reduce cuvintele la cea mai simplÄƒ formÄƒ a lor.\n",
        "\n",
        "Ãn cazul lematizÄƒrii cea mai simplÄƒ formÄƒ este forma de dicÈ›ionar È™i se numeÈ™te _lemÄƒ_. Stemmingul foloseÈ™te regex pentru a elimina prefixele È™i sufixele, ceea ce Ã®nseamnÄƒ cÄƒ un _stem_ nu reprezintÄƒ neapÄƒrat un cuvÃ¢nt real, sau poate reprezenta un alt cuvÃ¢nt deja existent.\n",
        "\n",
        "Ãn general folosim stemmingul cÃ¢nd vrem un rÄƒspuns rapid sau cÃ¢nd avem de-a face cu multe cuvinte scrise incorect (ca pe reÈ›elele de socializare)."
      ],
      "metadata": {
        "id": "k---xJS96EJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![1_HLQgkMt5-g5WO5VpNuTl_g.jpeg](https://miro.medium.com/max/564/1*HLQgkMt5-g5WO5VpNuTl_g.jpeg)"
      ],
      "metadata": {
        "id": "SYFj69rC1T3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aici este un exemplu de cum putem folosi lematizarea sau stemmingul pentru limba englezÄƒ:"
      ],
      "metadata": {
        "id": "rzKROdKPfIvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "uaC3VE7GfxvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"leaves\""
      ],
      "metadata": {
        "id": "Z9jeWhD321z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(f\"{word} :\", lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrEn9Ytl1ycZ",
        "outputId": "11133c52-e807-4912-b407-fa4da37cee34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "leaves : leaf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "print(f\"{word} :\", stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjH_MhOY2poF",
        "outputId": "22639455-61a8-49a1-9b3b-38922c537be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "leaves : leav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cuvinte comune (Stopwords)\n",
        "\n",
        "Stopwords reprezintÄƒ cele mai des utilizate cuvinte dintr-o limbÄƒ. DeÈ™i au valoare sintacticÄƒ È™i morfologicÄƒ, stopwords nu au foarte multÄƒ valoare semanticÄƒ. Cele mai multe sunt pronume (\"we\"), prepoziÈ›ii (\"for\") sau conjuncÈ›ii (\"and\"), dar putem regÄƒsi È™i verbe (\"is\") sau numerale (\"two\").\n",
        "\n",
        "[Fun fact](https://www.youtube.com/watch?v=fCn8zs912OE)"
      ],
      "metadata": {
        "id": "91W7wg7b6HY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZS8k63_rXB0",
        "outputId": "5aae5792-c91d-436c-ed3f-495211f3c4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words_nltk = set(stopwords.words('english'))\n",
        "print(stop_words_nltk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4gju2Q9zUft",
        "outputId": "ce4659c7-1c40-4bee-eca0-3f203443d37f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'through', 'on', 'each', 'out', \"don't\", 'me', 'o', 'in', \"won't\", 'before', \"that'll\", 'm', 'ourselves', \"shouldn't\", 'nor', 'it', \"you'll\", 'has', 'all', 'some', 're', 'to', 'did', 'with', \"wasn't\", 'this', \"isn't\", 'during', 'further', \"haven't\", 'while', 'the', 'over', 'couldn', 'same', 'and', 'have', 'here', \"she's\", 'between', 'aren', \"hasn't\", 'had', 'by', 'other', 'because', \"weren't\", 'than', 't', 'haven', 'until', 'but', 'y', \"couldn't\", 'why', 'do', 've', \"needn't\", 'yourselves', 'having', 's', 'is', 'just', 'isn', 'theirs', 'their', 'myself', 'whom', 'him', 'where', 'yours', 'hasn', 'doing', 'being', \"you'd\", 'they', 'were', 'if', 'shan', 'wasn', 'as', \"should've\", 'll', \"mustn't\", 'off', 'we', 'own', 'under', 'too', \"aren't\", 'shouldn', 'i', 'ma', 'he', 'above', 'once', 'will', 'against', 'his', 'hadn', 'ain', \"didn't\", 'that', 'how', 'there', 'most', 'hers', 'itself', 'our', \"hadn't\", 'then', \"doesn't\", 'd', 'her', 'them', 'be', 'very', 'can', 'she', 'more', 'ours', \"you're\", 'you', 'of', 'your', 'don', 'doesn', 'mightn', 'below', \"wouldn't\", 'both', 'needn', 'should', \"it's\", 'or', 'for', 'won', 'which', 'been', 'so', 'what', 'was', 'only', 'themselves', 'are', 'who', \"mightn't\", 'an', 'again', \"you've\", 'herself', 'few', 'himself', 'when', 'weren', 'its', 'a', 'down', 'not', \"shan't\", 'those', 'no', 'now', 'my', 'these', 'am', 'any', 'after', 'yourself', 'wouldn', 'from', 'about', 'mustn', 'such', 'didn', 'up', 'at', 'into', 'does'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ExerciÈ›ii\n",
        "\n",
        "\n",
        "\n",
        "1. Scrie o funcÈ›ie care Ã®mparte un text Ã®n tokeni folosind regex.\n",
        "2. Scrie o funcÈ›ie care Ã®nlocuieÈ™te toate emoticoanele (nu doar cele date ca exemplu) È™i emojiurile din text.\n",
        "3. Scrie o funcÈ›ie care primeÈ™te un text È™i returneazÄƒ varianta preprocesatÄƒ. FuncÈ›ia va converti toate numerele Ã®n cuvinte folosind [num2words](https://pypi.org/project/num2words/), va elimina linkurile, hashtagurile, mentions, punctuaÈ›ia, stopwords, va face toate textele literÄƒ micÄƒ È™i va aplica lematizarea sau stemming.\n",
        "4. AnalizeazÄƒ setul de date. UitÄƒ-te la elemente de preprocesare sau alte features folosind ce aÈ›i Ã®nvÄƒÈ›at Ã®n primul laborator. Ce pare important?\n",
        "5. Pe baza analizei anterioare scrie o funcÈ›ie de preprocesare care eliminÄƒ doar informaÈ›ia irelevantÄƒ. PoÈ›i generaliza funcÈ›ia originalÄƒ specificÃ¢nd Ã®n lista de parametri ce modificÄƒri vrei sÄƒ faci la apelarea funcÈ›iei. Alternativ, poÈ›i face o clasÄƒ care include o serie de funcÈ›ii care pot fi alese la iniÈ›ializare. Cu cÃ¢t e mai general cu atÃ¢t mai bine.\n",
        "6. ComparÄƒ metodele de preprocesare."
      ],
      "metadata": {
        "id": "eJhncK_LaaV8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8qAw2Fm344LI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}